# mitigate_bias

In this project we try to mitigate bias in LLMs by introdusing multi-agents using think tools. 

Our result shows that this method works, you can check project description completely here.

The result was trully interesting. multi-agent sometimes try to answer even more crefull that dataset.

